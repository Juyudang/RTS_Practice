# Part 1.  Collect/Simple Processing + Store + visualization

## 1. Logstash (Collect)

### logstash를 이용하여 데이터를 수집하는 Quick guide
 - https://www.elastic.co/guide/en/logstash/current/getting-started-with-logstash.html

- logstash 구성도
![logstash 구조]
(https://www.elastic.co/guide/en/logstash/current/static/images/basic_logstash_pipeline.png)


## 2. elasticsearch

### elasticsearch에 대한 기본 개념 이해
- https://www.elastic.co/guide/en/elasticsearch/reference/current/getting-started.html

## 3. kibana
- elasticsearch에 저장된 데이터를 시각화 해주는 web dash-board
 - https://www.elastic.co/guide/en/kibana/current/getting-started.html


# [Part 2]. Apache log 시각화 실습
## 1. Install
### elasticsearch 6.2 설치 및 실행

- 설치

```
> cd ~
> curl -L -O https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.2.4.tar.gz
> tar xvf elasticsearch-2.4.0.tar.gz
> cd elasticsearch-6.2.4/

# install plugin
> bin/elasticsearch-plugin install ingest-user-agent
> bin/elasticsearch-plugin install ingest-geoip

# config 설정
> vi config/elasticsearch.yml
# 아래의 코드 추가 (외부 접속 허용)
 network.host: 0.0.0.0
```

- 사전 OS 설정
  * virtual memory error 해결
  * 시스템의 nmap count를 증가기켜야 한다.
  * https://www.elastic.co/guide/en/elasticsearch/reference/current/vm-max-map-count.html
```
> sudo sysctl -w vm.max_map_count=262144
```
  * file descriptor 갯수를 증가시켜야 한다.
  * max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536]
  * https://www.elastic.co/guide/en/elasticsearch/reference/current/setting-system-settings.html#limits.conf
```
> sudo vi /etc/security/limits.conf
# 아래 내용 추가 (rts는 사용자 계정명)
> rts              -       nofile          65536
```

 - 실행

```
> ~/elasticsearch-6.2.4/bin/elasticsearch

//정상동작 확인 (Web browser에서 아래 주소 입력하면 결과 json 확인)
http://<ip>:9200

{
"name": "Norrin Radd",
"cluster_name": "elasticsearch",
"version": {
"number": "2.4.0",
"build_hash": "ce9f0c7394dee074091dd1bc4e9469251181fc55",
"build_timestamp": "2016-08-29T09:14:17Z",
"build_snapshot": false,
"lucene_version": "5.5.2"
},
"tagline": "You Know, for Search"
}
```

### kibana 6.2.4 설치 및 실행

```
> wget https://download.elastic.co/kibana/kibana/kibana-4.6.1-linux-x86_64.tar.gz
> tar -xzf kibana-6.2.4-linux-x86_64.tar.gz
> cd kibana-6.2.4-linux-x86_64/

# 외부 접속 허용을 위한 설정
> vi config/kibana.yml
server.host: "0.0.0.0"

> bin/kibana
```

### logstash 설치 및 실행

- 사전 설정
```
# java 설치
> java -version
```

- 설치
```
> wget https://artifacts.elastic.co/downloads/logstash/logstash-6.2.4.tar.gz
> tar xvf logstash-6.2.4.tar.gz
> cd logstash-6.2.4
```

- logstash의 정상동작 확인

```
> bin/logstash -e 'input { stdin { } } output { stdout {} }'

// 정상동작 확인을 위한 메세지 입력 후 엔터
checking logstash

// 아래와 같은 메세지가 나오면 정상
[2018-05-02T20:01:49,354][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
test
{
      "@version" => "1",
       "message" => "test",
          "host" => "dev02",
    "@timestamp" => 2018-05-02T11:02:06.266Z
}

//Ctrl + D로 종료
```


## 2. logstash를 이용하여 apache log를 elasticsearch에 저장

- 저장할 log 데이터 생성

```
> cd ~
> mkdir logs
> cd logs
> wget https://raw.githubusercontent.com/elastic/examples/master/Common%20Data%20Formats/apache_logs/apache_logs


# apache log 확인
> head apache_logs
//아래와 같은 구조로 생성된 apache log 확인
83.149.9.216 - - [17/May/2015:10:05:03 +0000] "GET /presentations/logstash-monitorama-2013/images/kibana-search.png HTTP/1.1" 200 203023 "http://semicomplete.com/presentations/logstash-monitorama-2013/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1700.77 Safari/537.36"
```

- logstash 환경설정

```
> wget https://raw.githubusercontent.com/elastic/examples/master/Common%20Data%20Formats/apache_logs/logstash/apache_template.json
# template 버전이 6.0으로 작성되어 _all keywords가 disable되었음
# 따라서 해당 keywords를 삭제한다.
"_all": {
   "enabled": true
}

> wget https://raw.githubusercontent.com/elastic/examples/master/Common%20Data%20Formats/apache_logs/logstash/apache_logstash.conf
> vi apache_logstash.conf

input {  
  stdin { }
}


filter {
  grok {
    match => {
      "message" => '%{IPORHOST:clientip} %{USER:ident} %{USER:auth} \[%{HTTPDATE:timestamp}\] "%{WORD:verb} %{DATA:request} HTTP/%{NUMBER:httpversion}" %{NUMBER:response:int} (?:-|%{NUMBER:bytes:int}) %{QS:referrer} %{QS:agent}'
    }
  }

  date {
    match => [ "timestamp", "dd/MMM/YYYY:HH:mm:ss Z" ]
    locale => en
  }

  geoip {
    source => "clientip"
  }

  useragent {
    source => "agent"
    target => "useragent"
  }
}

output {
  stdout {
    codec => dots {}
  }

  elasticsearch {
    index => "apache_elastic_example"
    template => "./apache_template.json"
    template_name => "apache_elastic_example"
    template_overwrite => true
  }
}
```

- 실제 환경설정 정보
 - input은 표준입력으로 받음 (이번 실습에서는 cat으로 읽은 파일을 |으로 연결하여 입력)
 - filter는 apache log를 파싱하는데 필요한 설정(elasticsearch에 저장할 필드명과 변수 매핑)
 - output은 elasticsearch의 서버정보, index명, index 생성에 필요한 templagee 등을 설정 (이번 실습에서 index는 "apache_elk_example", 나중에 kibana에서 이 index명으로 시각화)

- logstash 실행

```
> cd ~/logs
> cat apache_logs | ~/logstash-6.2.4/bin/logstash -f apache_logstash.conf
```

- 결과 확인 (웹브라우저)) -> 10,000 건의 apache log를 정상적으로 저장
http://localhost:9200/apache_elastic_example/_count
```
{
"count": 10000,
  "_shards": {
    "total": 5,
    "successful": 5,
    "failed": 0
  }
}
```

## 3. kibana로 시각화 하기.

- kibana 접속 (http://<ip>:5601/)
- elasticsearch에 저장된 index를 조회 (logstash에서 자동으로 생성했음.)
 -  "Management >> Index Patterns >> Index name or pattern" 여기에 index 명을 입력 (apache_elastic_example)
 - 그럼 아래의 create 버튼이 보임 -> 클릭. (timestamp는 logstash에서 설정했으므로 나타남. timestamp를 설정하지 않으면 kibana에서 정상적으로 확인이 어려움.)
 - index의 필드명을 화인할 수 있다.

- 시각화 해보기.
 -  "Management >> Saved Objects >> Import", and select apache_kibana.json
 - https://github.com/elastic/examples/blob/master/Common%20Data%20Formats/apache_logs/logstash/apache_kibana.json
 - 이 json은 사용자가 만든 dash-board를 json형식으로 미리 저장한 파일임.
 - 이 파일을 import하면 리스트에 dash-board명이 나타남.
 - dash-board는 1개이고, 이를 구성하는 visualization은 10개
 - 리스트에 dash-board명을 더블클릭하면 상세 json구조가 보이고,
 - 화면 상위에 "View dashboard" 버튼을 클릭하면 시가화된 데이터가 보인다.


# [Part 3]. 실시간 Twitter trend 시각화 실습
## 1. Install
- Part 2에서 설치한 가이드와 동일

## 2. logstash를 이용하여 twitter 데이터 수집 및 elasticsearch에 저장

- 작업공간으로 이동
```
cd /home/rts/elk/examples/ElasticStack_twitter
```

- logstash 환경설정

```
vi twitter_logstash.conf

// 아래 항목에 twitter에 등록한 key 정보를 입력
input {
  twitter {
    consumer_key       => "INSERT YOUR CONSUMER KEY"
    consumer_secret    => "INSERT YOUR CONSUMER SECRET"
    oauth_token        => "INSERT YOUR ACCESS TOKEN"
    oauth_token_secret => "INSERT YOUR ACCESS TOKEN SECRET"
    keywords           => [ "thor", "spiderman", "wolverine", "ironman", "hulk"]
    full_tweet         => true
  }
}
```
https://github.com/elastic/examples/blob/master/ElasticStack_twitter/twitter_logstash.conf 참고

- logstash 실행

```
~/elk/logstash-2.4.0/bin/logstash -f twitter_logstash.conf
// 아래 메세지가 출력되면 정상
Settings: Default pipeline workers: 1
Pipeline main started
........
```

- 정상적으로 elasticsearch에 저장되는지 확인
http://14.63.218.130:9200/twitter_elk_example/_count
```
{
"count": 43,  // count가 점차 증가함을 볼 수 있다.
  "_shards": {
    "total": 1,
    "successful": 1,
    "failed": 0
  }
}
```

## 3. Kibana로 시각화 하기
- kibana 접속 (http://14.63.218.130:5601/)
- elasticsearch에 저장된 index를 조회 (logstash에서 자동으로 생성했음.)
 -  "Settings tab >> Indices tab >> Index name or pattern" 여기에 index 명을 입력 (twitter_elk_example)
 - 그럼 아래의 create 버튼이 보임 -> 클릭. (timestamp는 logstash에서 설정했으므로 나타남. timestamp를 설정하지 않으면 kibana에서 정상적으로 확인이 어려움.)
 - index의 필드명을 화인할 수 있다.

- 시각화 해보기.
 -  "Settings tab >> Objects tab >> Import", and select twitter_kibana.json
 - 이 json은 사용자가 만든 dash-board를 json형식으로 미리 저장한 파일임.
 - 이 파일을 import하면 리스트에 dash-board명이 나타남.
 - dash-board는 1개이고, 이를 구성하는 visualization은 10개
 - 리스트에 dash-board명을 더블클릭하면 상세 json구조가 보이고,
 - 화면 상위에 "View dashboard" 버튼을 클릭하면 시가화된 데이터가 보인다.


# [Part 4]. FileBeat를 이용한 수집



여기서 사용된 예제는 elasticsearch git에서 제공하는 자료를 이용하였음.
https://github.com/elastic/examples
