## 1. Collection(Apache Flume)

- Flume Quick Glance
http://www.slideshare.net/madvirus/flume-29149433

### 0. Prerequisite
- 실습에 필요한 라이브러리 설치
```
# Java 설치 및 JAVA_HOME 설정
> sudo yum install -y java
> export JAVA_HOME=$(alternatives --display java | grep current | sed 's/link currently points to //' | sed 's|/bin/java||')
> echo $JAVA_HOME
```

```
> sudo yum install -y wget
```

### 1-1. Let's install
 * Step 1: Download latest Flume release from Apache [Website](http://archive.apache.org/dist/flume/)
```
  > cd ~
  > mkdir apps
  > cd apps
  > wget http://apache.mirror.cdnetworks.com/flume/1.8.0/apache-flume-1.8.0-bin.tar.gz
  > tar xvf apache-flume-1.8.0-bin.tar.gz
```

 * Step 2: Configure Environment Setting
```
> export PATH=$PATH:~/apps/apache-flume-1.8.0-bin/bin
```

 * Step 3: Flume Config Setting

```
> cd ~/apps/apache-flume-1.8.0-bin/conf/
> cp flume-env.sh.template flume-env.sh

> flume-ng --help //명령어가 정상적으로 동작하는지 확인
```
### 1-2. Flume Basic Example

#### Example 1 : Sequence Generation
- 임의의 데이터를 생성하여 log파일로 저장한다.
```
> cd ~/apps/apache-flume-1.8.0-bin/conf/
> vi seq.conf
```

```
# 아래의 내용을 입력한다.
a1.sources = r1
a1.channels = c1
a1.sinks = s1

a1.sources.r1.type = seq
a1.sources.r1.channels = c1

a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

a1.sinks.s1.type = logger
a1.sinks.s1.channel = c1
```

- flume 실행
```
> cd ~/apps/apache-flume-1.8.0-bin
> ./bin/flume-ng agent -C conf -f conf/seq.conf -name a1
```

- 수집 결과 확인
```
  > cd ~/apps/apache-flume-1.8.0-bin
  > tail -f logs/flume.log
  # 아래와 같은 로그 확인
  08 Oct 2018 05:30:37,499 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.LoggerSink.process:95)  - Event: { headers:{} body: 30                                              0 }
08 Oct 2018 05:30:37,499 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.LoggerSink.process:95)  - Event: { headers:{} body: 31                                              1 }
08 Oct 2018 05:30:37,499 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.LoggerSink.process:95)  - Event: { headers:{} body: 32                                              2 }
  ```

#### Example 2 :  Exec Source (Tail file command)
  - 특정 디렉토리에 있는 파일의 변경사항을 실시간으로 읽어와서 log파일에 저장한다.
```
> cd ~/apps/apache-flume-1.8.0-bin/conf

# 1) config file 생성
> vi exec-tail.conf
# 아래의 내용을 입력한다.
a1.sources = r1
a1.channels = c1
a1.sinks = s1

a1.sources.r1.type = exec
a1.sources.r1.command = tail -F /home/<본인 계정>/apps/apache-flume-1.8.0-bin/test.log
a1.sources.r1.channels = c1

a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

a1.sinks.s1.type = logger
a1.sinks.s1.channel = c1

# 2) flume agent를 시작한다.
> cd ~/apps/apache-flume-1.8.0-bin
> bin/flume-ng agent -C conf -f conf/exec-tail.conf -name a1

# 3) test.log 파일에 새로운 내용을 입력되는지 tail을 통해서 모니터링
> cd ~/apps/apache-flume-1.8.0-bin
> tail -f logs/flume.log

# 4) test.log 파일에 새로운 내용을 추가한다.
> cd ~/apps/apache-flume-1.8.0-bin
> echo "test success" >> test.log
> echo "Good" >> test.log

# 5) tail -f logs/fume.log에 정상적으로 출력되는지 확인
```

#### Example 2 :  Exec Source (Run Command)
  - bash shell을 실행하고, 그 결과를 로그에 저장한다.
```
> cd ~/apps/apache-flume-1.8.0-bin/conf

# 1) config file 생성
> vi exec-shell.conf
# 아래의 내용을 입력한다.
a1.sources = r1
a1.channels = c1
a1.sinks = s1

a1.sources.r1.type = exec
a1.sources.r1.shell = /bin/bash -c
a1.sources.r1.command = for i in /home/rts/apps/apache-flume-1.6.0-bin/*; do cat $i; done
a1.sources.r1.channels = c1

a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

a1.sinks.s1.type = logger
a1.sinks.s1.channel = c1

# 2) flume agent를 시작한다.
> cd ~/apps/apache-flume-1.8.0-bin
> bin/flume-ng agent -C conf -f conf/exec-shell.conf -name a1

# 3) test.log 파일에 새로운 내용을 입력되는지 tail을 통해서 모니터링
> cd ~/apps/apache-flume-1.8.0-bin/logs/
> tail -f flume.log
```

#### Example 4 : File Roll sink

```
> cd ~/apps/apache-flume-1.8.0-bin/conf
> mkdir /tmp/flume

# 1) config file 생성
> vi nc-filerole-sink.conf


a1.sources = r1
a1.channels = c1
a1.sinks = s1

a1.sources.r1.type = netcat
a1.sources.r1.bind = localhost
a1.sources.r1.port = 56565
a1.sources.r1.channels = c1

a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

a1.sinks.s1.type = file_roll
a1.sinks.s1.channel = c1
a1.sinks.s1.sink.directory = /tmp/flume
a1.sinks.s1.sink.rollInterval= 60

# 2) flume agent 실행
> cd ~/apps/apache-flume-1.8.0-bin
> ./bin/flume-ng agent -c ./conf -f ./conf/nc-filerole-sink.conf -name a1 -Dflume.root.logger=INFO,console

# 3) /tmp/flume 디렉토리에 수집된 데이터 확인
> cd /tmp/flume
```

#### Example 5 : File channel
- channel로 유입되는 데이터를 file에 보관하는 방식
- 속도는 메모리 기반에 비하여 느리지만, 데이터 유실이 없다.
```
> cd ~/apps/apache-flume-1.8.0-bin/conf

# 1) config file 생성
> vi nc-file-channel.conf

a1.sources = r1
a1.channels = c1
a1.sinks = s1

a1.sources.r1.type = netcat
a1.sources.r1.bind = localhost
a1.sources.r1.port = 56565
a1.sources.r1.channels = c1

a1.channels = c1
a1.channels.c1.type = file
a1.channels.c1.checkpointDir = /tmp/flume/checkpoint
a1.channels.c1.dataDirs = /tmp/flume/data

a1.sinks.s1.type = file_roll
a1.sinks.s1.channel = c1
a1.sinks.s1.sink.directory = /tmp/flume
a1.sinks.s1.sink.rollInterval= 60

# 2) flume agent 실행
> ./bin/flume-ng agent -c ./conf -f ./conf/nc-file-channel.conf -name a1 -Dflume.root.logger=INFO,console

# 3) checkpoint와 data 디렉토리에 데이터가 생성되고 있는지 확인
> ls /tmp/flume/data
> ls /tmp/flume/checkpoint
```

### 1-3. Flume Tutorial [link](http://www.tutorialspoint.com/apache_flume/)

#### Sample 1 :  Fetching Twitter Data
- sink를 logggerSink로 변경
```
# Naming the components on the current agent.
TwitterAgent.sources = Twitter
TwitterAgent.channels = MemChannel
TwitterAgent.sinks = loggerSink  //hadoop를 설치하지 않았기 때문에 logger로 변경함.

# Describing/Configuring the source
TwitterAgent.sources.Twitter.type = org.apache.flume.source.twitter.TwitterSource
TwitterAgent.sources.Twitter.consumerKey = consumerKey
TwitterAgent.sources.Twitter.consumerSecret = consumerSecret
TwitterAgent.sources.Twitter.accessToken = accessToken
TwitterAgent.sources.Twitter.accessTokenSecret = accessTokenSecret
TwitterAgent.sources.Twitter.keywords = tutorials point,java, bigdata, mapreduce, mahout, hbase, nosql

# Describing/Configuring the sink
TwitterAgent.sinks.loggerSink.type = logger

# Describing/Configuring the channel TwitterAgent.channels.MemChannel.type = memory
TwitterAgent.channels.MemChannel.type                   = memory
TwitterAgent.channels.MemChannel.capacity               = 10000
TwitterAgent.channels.MemChannel.transactionCapacity    = 100

# Binding the source and sink to the channel
TwitterAgent.sources.Twitter.channels = MemChannel
TwitterAgent.sinks.loggerSink.channel = MemChannel
```
- 실행

```
> bin/flume-ng agent --conf ./conf/ -f conf/twitter.conf -Dflume.root.logger=DEBUG,console -n TwitterAgent
  => 여기서 "/home/rts/apps/apache-flume-1.6.0-bin/conf/flume-env.sh: line 26: -Xmx20m=Xms500m -Xms1000m -Dcom.sun.management.jmxremote: command not found " 가 발생함.
  => conf/flume-env.sh에 JAVA_OPTS 설정이 잘못됨.
  => export를 앞에 추가해야 하는데, 그냥 JAVA_OPTS로 시작함. (현재 서버 메모리가 낮으므로 default로 사용하도록 주석처리)
- -Dflume.root.logger=DEBUG,console 옵션은 log를 file(logs/flume.logs)로 쌓지 않고, console로 출력만 하는 옵션임.
- 따라서 flume.log로 쌓고 싶다면 해당 옵션을 제거
> bin/flume-ng agent --conf ./conf/ -f conf/twitter.conf -n TwitterAgent
```
  -
  - 추가 설정
    * twitter에서 조회한 데이터는 FLUME_HOME/logs/flume.log에 저장됨.
    * 이 flume.log를 열어보면 "body: 4F 62 6A 01 02 16 61 76 72 6F 2E 73 63 68 65 6D"와 같은 문자열만 출력됨.
    * 해결방안
      * conf/log4j.properties 파일에서 "flume.root.logger=ALL,LOGFILE"로 변경
      * twitter
  - 결과 확인
   * TwitterAgent.sources.Twitter.keywords = tutorials point,java, bigdata, mapreduce, mahout, hbase, nosql에서 설정한 keyword에 대항하는 내용만 추출하고 있음.

#### Sample 2 : NetCat Source
 * Scenario : NecCat source를 이용하여 수집된 데이터를 logger를 통해 저장하는 예제
 * Configuring Flume
```
> cd ~/apps/apache-flume-1.8.0-bin/conf
> vi netcat.conf

#Naming the components on the current agent
NetcatAgent.sources = Netcat
NetcatAgent.channels = MemChannel
NetcatAgent.sinks = LoggerSink

# Describing/Configuring the source
NetcatAgent.sources.Netcat.type = netcat
NetcatAgent.sources.Netcat.bind = localhost
NetcatAgent.sources.Netcat.port = 56565

# Describing/Configuring the sink
NetcatAgent.sinks.LoggerSink.type = logger

# Describing/Configuring the channel
NetcatAgent.channels.MemChannel.type = memory
NetcatAgent.channels.MemChannel.capacity = 1000
NetcatAgent.channels.MemChannel.transactionCapacity = 100

# Bind the source and sink to the channel
NetcatAgent.sources.Netcat.channels = MemChannel
NetcatAgent.sinks.LoggerSink.channel = MemChannel
```
* Execute Flume

```
> cd ~/apps/apache-flume-1.8.0-bin
> bin/flume-ng agent --conf conf --conf-file conf/netcat.conf --name NetcatAgent -Dflume.root.logger=INFO,console
```

* Send message using Telnet

```
> curl telnet://localhost:56565
connected
```

#### Sample 3 : Flume Interceptor [link](http://hadoopathome.logdown.com/posts/293904-apache-flume-interceptors-modifying-the-event-body)
 * Flume Event는 header + body로 구성됨  
 ![flume evtns](http://i.imgur.com/uIe8eQE.png)
 * interceptor는 body 수정(filter, extract, add information ...)
 * Secnario : Sample2에 Interceptor를 삽입하여 timestamp가 출력되도록 한다.
 * java로 interceptor class를 구현하고 jar로 생성하여, FLUME_HOME/lib 아래로 복사한다.
  * [source project](https://github.com/benwatson528/flume-timestamp-body-interceptor)
  * 아래의 함수가 실제 event를 interceptor하여 조작하는 함수
  ```
  @Override
	public Event intercept(Event event) {
		byte[] eventBody = event.getBody();
		event.setBody(appendTimestampToBody(eventBody, System.nanoTime()));
		return event;
	}

	protected byte[] appendTimestampToBody(byte[] startEventBody, long time) {
		try {
			this.timeBytes = Long.toString(time).getBytes();
			this.outputBodyLength 	= startEventBody.length + this.separator.length + this.timeBytes.length;
			this.outputStream 		= new ByteArrayOutputStream(this.outputBodyLength);
			this.outputStream.write(startEventBody);
			this.outputStream.write(this.separator);
			this.outputStream.write(this.timeBytes);
			return this.outputStream.toByteArray();
		} catch (IOException ex) {
			this.logger.error("Couldn't add timestamp to body", ex);
			throw new RuntimeException("Couldn't add timestamp to body", ex);
		}
	}
  ```
 * config 파일 수정 (intercepor 추가)
```
> cd ~/apps/apache-flume-1.8.0-bin/conf
> cp netcat.conf interceptorNetcat.conf
> vi interceptorNetcat.conf

# 아래 내용을 추가.
# Describing/Configuring the interceptor
NetcatAgent.sources.Netcat.interceptors = i1
NetcatAgent.sources.Netcat.interceptors.i1.type = uk.co.hadoopathome.flume.timestampbodyinterceptor.TimestampBodyInterceptor$Builder
NetcatAgent.sources.Netcat.interceptors.i1.separator = , # 구분자를 ","로 지정함.
```

  * interceptor project build -> jar 생성
```
# 1 project download (기존에 생성한 예제 활용)
> sudo yum install -y git maven
> cd ~/apps
> git clone https://github.com/benwatson528/flume-timestamp-body-interceptor.git
> cd flume-timestamp-body-interceptor
> vi pom.xml
  flume-version을 현재 설치된 버전으로 수정한다. (1.6.0)

# jar 파일로 생성
> mvn clean package

# 생성된 jar를 flume에서 인식할 수 있는 경로로 이동
> cp target/timestamp-body-interceptor-1.0-SNAPSHOT.jar ~/apps/apache-flume-1.8.0-bin/lib/
```

  * flume 실행
```
> cd ~/apps/apache-flume-1.8.0-bin
> bin/flume-ng agent --conf conf --conf-file conf/interceptorNetcat.conf --name NetcatAgent -Dflume.root.logger=INFO,console
```
* telnet 실행

```
> curl telnet://localhost:56565
  test
  OK
```
 * 아래와 같이 "메제지 ,  System.nanoTime()" 이 출력되는 것을 확인
 * 이런 방식으로 메세지 입력 시점에 원하는 비즈니스 로직을 반영함.
```
Event: { headers:{} body: 68 69 2C 32 38 39 30 32 32 32 38 37 37 34 34 32 hi,2890222877442 }
```
