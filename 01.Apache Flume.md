## 1. Collection(Apache Flume)

- Flume Quick Glance
http://www.slideshare.net/madvirus/flume-29149433

### 0. Prerequisite
- 실습에 필요한 라이브러리 설치
```
# Java 설치 및 JAVA_HOME 설정
> sudo yum install -y java
> export JAVA_HOME=$(alternatives --display java | grep current | sed 's/link currently points to //' | sed 's|/bin/java||')
> echo $JAVA_HOME
```

```
> sudo yum install -y wget git
```

### 1-1. Let's install
 * Step 1: Download latest Flume release from Apache [Website](http://archive.apache.org/dist/flume/)
```
  > cd ~
  > mkdir apps
  > cd apps
  > wget http://apache.mirror.cdnetworks.com/flume/1.8.0/apache-flume-1.8.0-bin.tar.gz
  > tar xvf apache-flume-1.8.0-bin.tar.gz
```

 * Step 2: Configure Environment Setting
```
> export PATH=$PATH:~/apps/apache-flume-1.8.0-bin/bin
```

 * Step 3: Flume Config Setting

```
> cd ~/apps/apache-flume-1.8.0-bin/conf/
> cp flume-env.sh.template flume-env.sh

> flume-ng --help //명령어가 정상적으로 동작하는지 확인
```
### 1-2. Flume Basic Example

#### Example 1 : Sequence Generation
- 임의의 데이터를 생성하여 log파일로 저장한다.
```
> cd ~/apps/apache-flume-1.8.0-bin/conf/
> vi seq.conf
```

```
# 아래의 내용을 입력한다.
a1.sources = r1
a1.channels = c1
a1.sinks = s1

a1.sources.r1.type = seq
a1.sources.r1.channels = c1

a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

a1.sinks.s1.type = logger
a1.sinks.s1.channel = c1
```

- flume 실행
```
> cd ~/apps/apache-flume-1.8.0-bin
> ./bin/flume-ng agent -C conf -f conf/seq.conf -name a1
```

- 수집 결과 확인
```
> cd ~/apps/apache-flume-1.8.0-bin
> tail -f logs/flume.log
# 아래와 같은 로그 확인
...  Event: { headers:{} body: 30                                              0 }
...  Event: { headers:{} body: 31                                              1 }
...  Event: { headers:{} body: 32                                              2 }
```

#### Example 2 :  Exec Source (Tail file command)
  - 특정 디렉토리에 있는 파일의 변경사항을 실시간으로 읽어와서 log파일에 저장한다.
```
> cd ~/apps/apache-flume-1.8.0-bin/conf

# 1) config file 생성
> vi exec-tail.conf
# 아래의 내용을 입력한다.
a1.sources = r1
a1.channels = c1
a1.sinks = s1

a1.sources.r1.type = exec
a1.sources.r1.command = tail -F /home/<본인 계정>/apps/apache-flume-1.8.0-bin/test.log
a1.sources.r1.channels = c1

a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

a1.sinks.s1.type = logger
a1.sinks.s1.channel = c1

# 2) flume agent를 시작한다.
> cd ~/apps/apache-flume-1.8.0-bin
> bin/flume-ng agent -C conf -f conf/exec-tail.conf -name a1

# 3) test.log 파일에 새로운 내용을 입력되는지 tail을 통해서 모니터링
> cd ~/apps/apache-flume-1.8.0-bin
> tail -f logs/flume.log

# 4) test.log 파일에 새로운 내용을 추가한다.
> cd ~/apps/apache-flume-1.8.0-bin
> echo "test success" >> test.log
> echo "Good" >> test.log

# 5) tail -f logs/fume.log에 정상적으로 출력되는지 확인
```

#### Example 2 :  Exec Source (Run Command)
  - bash shell을 실행하고, 그 결과를 로그에 저장한다.
```
> cd ~/apps/apache-flume-1.8.0-bin/conf

# 1) config file 생성
> vi exec-shell.conf
# 아래의 내용을 입력한다.
a1.sources = r1
a1.channels = c1
a1.sinks = s1

a1.sources.r1.type = exec
a1.sources.r1.shell = /bin/bash -c
a1.sources.r1.command = for i in /home/rts/apps/apache-flume-1.6.0-bin/*; do cat $i; done
a1.sources.r1.channels = c1

a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

a1.sinks.s1.type = logger
a1.sinks.s1.channel = c1

# 2) flume agent를 시작한다.
> cd ~/apps/apache-flume-1.8.0-bin
> bin/flume-ng agent -C conf -f conf/exec-shell.conf -name a1

# 3) test.log 파일에 새로운 내용을 입력되는지 tail을 통해서 모니터링
> cd ~/apps/apache-flume-1.8.0-bin/logs/
> tail -f flume.log
```

#### Example 3 : NetCat Source
 * Scenario : NecCat source를 이용하여 수집된 데이터를 logger를 통해 저장하는 예제
 * Configuring Flume
```
> cd ~/apps/apache-flume-1.8.0-bin/conf
> vi netcat.conf

#Naming the components on the current agent
NetcatAgent.sources = Netcat
NetcatAgent.channels = MemChannel
NetcatAgent.sinks = LoggerSink

# Describing/Configuring the source
NetcatAgent.sources.Netcat.type = netcat
NetcatAgent.sources.Netcat.bind = localhost
NetcatAgent.sources.Netcat.port = 56565

# Describing/Configuring the sink
NetcatAgent.sinks.LoggerSink.type = logger

# Describing/Configuring the channel
NetcatAgent.channels.MemChannel.type = memory
NetcatAgent.channels.MemChannel.capacity = 1000
NetcatAgent.channels.MemChannel.transactionCapacity = 100

# Bind the source and sink to the channel
NetcatAgent.sources.Netcat.channels = MemChannel
NetcatAgent.sinks.LoggerSink.channel = MemChannel
```
* Execute Flume

```
> cd ~/apps/apache-flume-1.8.0-bin
> bin/flume-ng agent --conf conf --conf-file conf/netcat.conf --name NetcatAgent -Dflume.root.logger=INFO,console
```

* Send message using Telnet
```
> curl telnet://localhost:56565
connected
```

#### Example 4 : File Roll sink

```
> cd ~/apps/apache-flume-1.8.0-bin/conf
> mkdir /tmp/flume

# 1) config file 생성
> vi nc-filerole-sink.conf


a1.sources = r1
a1.channels = c1
a1.sinks = s1

a1.sources.r1.type = netcat
a1.sources.r1.bind = localhost
a1.sources.r1.port = 56565
a1.sources.r1.channels = c1

a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

a1.sinks.s1.type = file_roll
a1.sinks.s1.channel = c1
a1.sinks.s1.sink.directory = /tmp/flume
a1.sinks.s1.sink.rollInterval= 60

# 2) flume agent 실행
> cd ~/apps/apache-flume-1.8.0-bin
> ./bin/flume-ng agent -c ./conf -f ./conf/nc-filerole-sink.conf -name a1 -Dflume.root.logger=INFO,console

# 3) Send message using Telnet
> curl telnet://localhost:56565
test message

# 4) /tmp/flume 디렉토리에 수집된 데이터 확인
> cd /tmp/flume
```

#### Example 5 : File channel
- channel로 유입되는 데이터를 file에 보관하는 방식
- 속도는 메모리 기반에 비하여 느리지만, 데이터 유실이 없다.
```
> cd ~/apps/apache-flume-1.8.0-bin/conf

# 1) config file 생성
> vi nc-file-channel.conf

a1.sources = r1
a1.channels = c1
a1.sinks = s1

a1.sources.r1.type = netcat
a1.sources.r1.bind = localhost
a1.sources.r1.port = 56565
a1.sources.r1.channels = c1

a1.channels = c1
a1.channels.c1.type = file
a1.channels.c1.checkpointDir = /tmp/flume/checkpoint
a1.channels.c1.dataDirs = /tmp/flume/data

a1.sinks.s1.type = file_roll
a1.sinks.s1.channel = c1
a1.sinks.s1.sink.directory = /tmp/flume
a1.sinks.s1.sink.rollInterval= 60

# 2) flume agent 실행
> cd ~/apps/apache-flume-1.8.0-bin/
> ./bin/flume-ng agent -c ./conf -f ./conf/nc-file-channel.conf -name a1 -Dflume.root.logger=INFO,console

# 3) Send message using Telnet
> curl telnet://localhost:56565
test message

# 4) checkpoint와 data 디렉토리에 데이터가 생성되고 있는지 확인
> ls /tmp/flume/data
> ls /tmp/flume/checkpoint
```

#### Example 6. Sink Processor (Load Balance)
- 수집된 데이터를 분산하여 여러개의 sink로 저장한다.
```
> cd ~/apps/apache-flume-1.8.0-bin/conf

# 1) config file 생성
> vi nc-sinkprocessor.conf

a1.sources = r1
a1.channels = c1
a1.sinks = s1 s2

a1.sources.r1.type = seq
a1.sources.r1.channels = c1

a1.sinkgroups = g1
a1.sinkgroups.g1.sinks = s1 s2
a1.sinkgroups.g1.processor.type = load_balance
a1.sinkgroups.g1.processor.backoff = true
a1.sinkgroups.g1.processor.selector = round_robin

a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

a1.sinks.s1.type = file_roll
a1.sinks.s1.channel = c1
a1.sinks.s1.sink.directory = /tmp/flume
a1.sinks.s1.sink.rollInterval= 60

a1.sinks.s2.type = logger
a1.sinks.s2.channel = c1

# 2) flume agent 실행
> cd ~/apps/apache-flume-1.8.0-bin/
> ./bin/flume-ng agent -c ./conf -f ./conf/nc-sinkprocessor.conf -name a1 -Dflume.root.logger=INFO,console

# 3) 결과 확인
- s1 : console 에 출력된 숫자를 확인
- 100, 201, 302.. 등이 출력됨.
... Event: { headers:{} body: 31 30 30                                        100 }
... Event: { headers:{} body: 32 30 31                                        201 }
... Event: { headers:{} body: 33 30 32                                        302 }
... Event: { headers:{} body: 34 30 33                                        403 }
... Event: { headers:{} body: 35 30 34                                        504 }


- s2 : file에 출력된 결과를 확인
- vi vi /tmp/flume/<생성된 로그파일 명>

97
98
99
101  --> log로 전달된 100은 제외하고 출력됨. (load balancing이 정상 처리됨)
102

```

#### Example 7. Channel Selector (Multiplexing)
- 단순히 전체 로그를 수집하는 방식이 아닌,
- 로그의 상태코드에 따라 다른 처리가 필요한 경우에 활용
- 예를 들어, 상태코드가 정상인 로그는 hdfs로 전달하고,
- 에러인 코드는 kafka로 전달하여, spark에서 별도의 처리를 하도록 분기할 필요가 있다.
- 이때 사용하는 사례로 channel selector를 이용할 수 있다.
- https://dzone.com/articles/apache-flume-to-multiplex-or-replicate-big-data 참고

##### 실습 데이터
- 총 4개의 칼럼으로 구성.
- employee_role에 따라서 channel을 선택하도록 구성
```
employee_role, employee_id, employee_name, employee_city.
```
- 데이터 샘플
```
Role,ID,Name,City
1, E1,Viren,mumbai
1, E3,Ofer,kolkata

2, E4,Sanjeev,delhi
2, E6,Amruta,banglore
```

- config 파일을 생성하고  실행

```
> cd ~/apps/apache-flume-1.8.0-bin/conf
> vi nc-channel-selecor.conf
-- 아래 내용 입력

a1.sources = r1
a1.sinks = k1 k2
a1.channels = c1 c2

# Describe/configure the source
a1.sources.r1.type = netcat
a1.sources.r1.bind = localhost
a1.sources.r1.port = 44444

# Use a channel c1 which buffers events in memory
a1.channels.c1.type = memory
a1.channels.c1.capacity = 100

# Use a channel c2 which buffers events in memory
a1.channels.c2.type = memory
a1.channels.c2.capacity = 100

# Describe regex_extractor to extract different patterns
# Capture event attribute and add it as event header with attribure name as "role"
a1.sources.r1.interceptors = i1
a1.sources.r1.interceptors.i1.type = regex_extractor
a1.sources.r1.interceptors.i1.regex = ^(\\d)
a1.sources.r1.interceptors.i1.serializers = t
a1.sources.r1.interceptors.i1.serializers.t.name = role

# Describe first File_roll sink k1 to store manager's data only, its associated with channel c1
a1.sinks.k1.type = file_roll
a1.sinks.k1.channel = c1
a1.sinks.k1.sink.directory = /tmp/flume
a1.sinks.k1.sink.rollInterval= 600


# Describe HDFS sink k2 to store developer's data only, its associated with channel c2
a1.sinks.k2.type = logger
a1.sinks.k2.channel = c2

# Define channel selector and define mapping
a1.sources.r1.selector.type = multiplexing
a1.sources.r1.selector.header = role
a1.sources.r1.selector.mapping.1 = c1
a1.sources.r1.selector.mapping.2 = c2
a1.sources.r1.selector.default = c2

# Bind the source and sink to the channel
a1.sources.r1.channels = c1 c2
```

- flume agent 실행
```
> cd ~ apps/apache-flume-1.8.0-bin/
> flume-ng agent --conf ./conf --conf-file ./conf/nc-channel-selecor.conf -name a1 -Dflume.root.logger=INFO,console
```

- 테스트 할 데이터 전송 (telnet 활용)
```
> curl telnet://localhost:44444
1, E1,Viren,mumbai
2, E2,John,chennai
1, E3,Ofer,kolkata
2, E4,Sanjeev,delhi
1, E5,Ramesh,pune
2, E6,Amruta,banglore
```

- 결과확인 sink1 : file_roll에 저장된 데이터 확인
```
> cd /tmp/flume
> cat 1539147516389-1
1, E1,Viren,mumbai
1, E3,Ofer,kolkata
1, E5,Ramesh,pune
```

- 결과 확인 sink2 : flume agent를 샐행한 console에서 확인
```
... Event: { headers:{role=2} body: 32 2C 20 45 32 2C 4A 6F 68 6E 2C 63 68 65 6E 6E 2, E2,John,chenn }
... Event: { headers:{role=2} body: 32 2C 20 45 34 2C 53 61 6E 6A 65 65 76 2C 64 65 2, E4,Sanjeev,de }

```

#### Example 8. Timestamp Interceptor
- event의 header에 현재 시간값을 추가한다.
```
> cd ~/apps/apache-flume-1.8.0-bin/conf/
> vi nc-time-interceptor.conf

a1.sources = r1
a1.channels = c1
a1.sinks = s1

a1.sources.r1.type = netcat
a1.sources.r1.bind = localhost
a1.sources.r1.port = 56565
a1.sources.r1.channels = c1

a1.sources.r1.interceptors = i1
a1.sources.r1.interceptors.i1.type = timestamp

a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

a1.sinks.s1.type = logger
a1.sinks.s1.channel = c1
```

- flume agent 실행
```
> cd ~/apps/apache-flume-1.8.0-bin/
> ./bin/flume-ng agent -c ./conf -f ./conf/nc-time-interceptor.conf -name a1 -Dflume.root.logger=INFO,console
```

- telnet으로 메세지 전달
```
> curl telnet://localhost:56565
test message 
```

- 결과 확인
- flume agent console에 timestamp 값이 출력됨.
```
...  Event: { headers:{timestamp=1539152345495} body: 74 65 73 74                                     test }
```


#### Example 9. Host Interceptor
- event의 header에 현재 시간값을 추가한다.
```
> cd ~/apps/apache-flume-1.8.0-bin/conf/
> vi nc-host-interceptor.conf

a1.sources = r1
a1.channels = c1
a1.sinks = s1

a1.sources.r1.type = netcat
a1.sources.r1.bind = localhost
a1.sources.r1.port = 56565
a1.sources.r1.channels = c1

a1.sources.r1.interceptors = i1 i2
a1.sources.r1.interceptors.i1.type = timestamp

a1.sources.r1.interceptors.i2.type = host
a1.sources.r1.interceptors.i2.hostHeader = hostname

a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

a1.sinks.s1.type = logger
a1.sinks.s1.channel = c1
```

- flume agent 실행
```
> cd ~/apps/apache-flume-1.8.0-bin/
> ./bin/flume-ng agent -c ./conf -f ./conf/nc-host-interceptor.conf -name a1 -Dflume.root.logger=INFO,console
```

- telnet으로 메세지 전달
```
> curl telnet://localhost:56565
test
```

- 결과 확인
- flume agent console에 timestamp 값이 출력됨.
```
...  Event: { headers:{hostname=10.146.0.6, timestamp=1539160119781} body: 74 65 73 74                                     test }
```

#### Example 10. Static Interceptor
- event의 header에 현재 시간값을 추가한다.
```
> cd ~/apps/apache-flume-1.8.0-bin/conf/
> vi nc-static-interceptor.conf

a1.sources = r1
a1.channels = c1
a1.sinks = s1

a1.sources.r1.type = netcat
a1.sources.r1.bind = localhost
a1.sources.r1.port = 56565
a1.sources.r1.channels = c1

a1.sources.r1.interceptors = i1
a1.sources.r1.interceptors.i1.type = static
a1.sources.r1.interceptors.i1.key = GENDER
a1.sources.r1.interceptors.i1.value = M

a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

a1.sinks.s1.type = logger
a1.sinks.s1.channel = c1
```

- flume agent 실행
```
> cd ~/apps/apache-flume-1.8.0-bin/
> ./bin/flume-ng agent -c ./conf -f ./conf/nc-static-interceptor.conf -name a1 -Dflume.root.logger=INFO,console
```

- telnet으로 메세지 전달
```
> curl telnet://localhost:56565
test
```

- 결과 확인
- flume agent console에 timestamp 값이 출력됨.
```
...  Event: { headers:{GENDER=M} body: 74 65 73 74                                     test }
```

#### Example 11. UUID Interceptor
- event의 header에 현재 시간값을 추가한다.
```
> cd ~/apps/apache-flume-1.8.0-bin/conf/
> vi nc-uuid-interceptor.conf

a1.sources = r1
a1.channels = c1
a1.sinks = s1

a1.sources.r1.type = netcat
a1.sources.r1.bind = localhost
a1.sources.r1.port = 56565
a1.sources.r1.channels = c1

a1.sources.r1.interceptors = i1
a1.sources.r1.interceptors.i1.type = org.apache.flume.sink.solr.morphline.UUIDInterceptor$Builder
a1.sources.r1.interceptors.i1.headerName = uuid
a1.sources.r1.interceptors.i1.prefix = C

a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

a1.sinks.s1.type = logger
a1.sinks.s1.channel = c1
```

- flume agent 실행
```
> cd ~/apps/apache-flume-1.8.0-bin/
> ./bin/flume-ng agent -c ./conf -f ./conf/nc-uuid-interceptor.conf -name a1 -Dflume.root.logger=INFO,console
```

- telnet으로 메세지 전달
```
> curl telnet://localhost:56565
test
```

- 결과 확인
- flume agent console에 timestamp 값이 출력됨.
```
... Event: { headers:{uuid=C1490aada-2582-4103-911c-2a7d36f5dce1} body: 74 65 73 74                                     test }
```


#### Example 12. Morphline Interceptor
- event의 header에 현재 시간값을 추가한다.
```
> cd ~/apps/apache-flume-1.8.0-bin/conf/
> vi nc-morphline-interceptor.conf

a1.sources = r1
a1.channels = c1
a1.sinks = s1

a1.sources.r1.type = netcat
a1.sources.r1.bind = localhost
a1.sources.r1.port = 56565
a1.sources.r1.channels = c1

a1.sources.r1.interceptors = i1
a1.sources.r1.interceptors.i1.type = search_replace
a1.sources.r1.interceptors.i1.searchPattern = test
a1.sources.r1.interceptors.i1.replaceString = banana

a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

a1.sinks.s1.type = logger
a1.sinks.s1.channel = c1
```

- flume agent 실행
```
> cd ~/apps/apache-flume-1.8.0-bin/
> ./bin/flume-ng agent -c ./conf -f ./conf/nc-morphline-interceptor.conf -name a1 -Dflume.root.logger=INFO,console
```

- telnet으로 메세지 전달
```
> curl telnet://localhost:56565
test
```

- 결과 확인
- flume agent console에 timestamp 값이 출력됨.
```
... Event: { headers:{} body: 62 61 6E 61 6E 61                               banana }
```

#### Example 20 : Flume Custom Interceptor [link](http://hadoopathome.logdown.com/posts/293904-apache-flume-interceptors-modifying-the-event-body)
 * Flume Event는 header + body로 구성됨  
 ![flume evtns](http://i.imgur.com/uIe8eQE.png)
 * interceptor는 body 수정(filter, extract, add information ...)
 * Secnario : Sample2에 Interceptor를 삽입하여 timestamp가 출력되도록 한다.
 * java로 interceptor class를 구현하고 jar로 생성하여, FLUME_HOME/lib 아래로 복사한다.
  * [source project](https://github.com/benwatson528/flume-timestamp-body-interceptor)
  * 아래의 함수가 실제 event를 interceptor하여 조작하는 함수
  * org.apache.flume.interceptor.Interceptor 인터페이스를 상속받아 원하는 body 처리 로직을 추가한다.
  ```
  @Override
	public Event intercept(Event event) {
		byte[] eventBody = event.getBody();
		event.setBody(appendTimestampToBody(eventBody, System.nanoTime()));
		return event;
	}

	protected byte[] appendTimestampToBody(byte[] startEventBody, long time) {
		try {
			this.timeBytes = Long.toString(time).getBytes();
			this.outputBodyLength 	= startEventBody.length + this.separator.length + this.timeBytes.length;
			this.outputStream 		= new ByteArrayOutputStream(this.outputBodyLength);
			this.outputStream.write(startEventBody);
			this.outputStream.write(this.separator);
			this.outputStream.write(this.timeBytes);
			return this.outputStream.toByteArray();
		} catch (IOException ex) {
			this.logger.error("Couldn't add timestamp to body", ex);
			throw new RuntimeException("Couldn't add timestamp to body", ex);
		}
	}
  ```
 * config 파일 수정 (intercepor 추가)
```
> cd ~/apps/apache-flume-1.8.0-bin/conf
> cp netcat.conf interceptorNetcat.conf
> vi interceptorNetcat.conf

# 아래 내용을 추가.
# Describing/Configuring the interceptor
NetcatAgent.sources.Netcat.interceptors = i1
NetcatAgent.sources.Netcat.interceptors.i1.type = uk.co.hadoopathome.flume.timestampbodyinterceptor.TimestampBodyInterceptor$Builder
NetcatAgent.sources.Netcat.interceptors.i1.separator = , # 구분자를 ","로 지정함.
```

  * interceptor project build -> jar 생성
```
# 1 project download (기존에 생성한 예제 활용)
> sudo yum install -y git maven
> cd ~/apps
> git clone https://github.com/benwatson528/flume-timestamp-body-interceptor.git
> cd flume-timestamp-body-interceptor
> vi pom.xml
  flume-version을 현재 설치된 버전으로 수정한다. (1.6.0)

# jar 파일로 생성
> mvn clean package

# 생성된 jar를 flume에서 인식할 수 있는 경로로 이동
> cp target/timestamp-body-interceptor-1.0-SNAPSHOT.jar ~/apps/apache-flume-1.8.0-bin/lib/
```

  * flume 실행
```
> cd ~/apps/apache-flume-1.8.0-bin
> bin/flume-ng agent --conf conf --conf-file conf/interceptorNetcat.conf --name NetcatAgent -Dflume.root.logger=INFO,console
```
* telnet 실행

```
> curl telnet://localhost:56565
  test
  OK
```
 * 아래와 같이 "메제지 ,  System.nanoTime()" 이 출력되는 것을 확인
 * 이런 방식으로 메세지 입력 시점에 원하는 비즈니스 로직을 반영함.
```
Event: { headers:{} body: 68 69 2C 32 38 39 30 32 32 32 38 37 37 34 34 32 hi,2890222877442 }
```





### 1-3. Flume Tutorial [link](http://www.tutorialspoint.com/apache_flume/)

#### Sample 1 :  Fetching Twitter Data
- sink를 logggerSink로 변경
```
# Naming the components on the current agent.
TwitterAgent.sources = Twitter
TwitterAgent.channels = MemChannel
TwitterAgent.sinks = loggerSink  //hadoop를 설치하지 않았기 때문에 logger로 변경함.

# Describing/Configuring the source
TwitterAgent.sources.Twitter.type = org.apache.flume.source.twitter.TwitterSource
TwitterAgent.sources.Twitter.consumerKey = consumerKey
TwitterAgent.sources.Twitter.consumerSecret = consumerSecret
TwitterAgent.sources.Twitter.accessToken = accessToken
TwitterAgent.sources.Twitter.accessTokenSecret = accessTokenSecret
TwitterAgent.sources.Twitter.keywords = tutorials point,java, bigdata, mapreduce, mahout, hbase, nosql

# Describing/Configuring the sink
TwitterAgent.sinks.loggerSink.type = logger

# Describing/Configuring the channel TwitterAgent.channels.MemChannel.type = memory
TwitterAgent.channels.MemChannel.type                   = memory
TwitterAgent.channels.MemChannel.capacity               = 10000
TwitterAgent.channels.MemChannel.transactionCapacity    = 100

# Binding the source and sink to the channel
TwitterAgent.sources.Twitter.channels = MemChannel
TwitterAgent.sinks.loggerSink.channel = MemChannel
```
- 실행

```
> bin/flume-ng agent --conf ./conf/ -f conf/twitter.conf -Dflume.root.logger=DEBUG,console -n TwitterAgent
  => 여기서 "/home/rts/apps/apache-flume-1.6.0-bin/conf/flume-env.sh: line 26: -Xmx20m=Xms500m -Xms1000m -Dcom.sun.management.jmxremote: command not found " 가 발생함.
  => conf/flume-env.sh에 JAVA_OPTS 설정이 잘못됨.
  => export를 앞에 추가해야 하는데, 그냥 JAVA_OPTS로 시작함. (현재 서버 메모리가 낮으므로 default로 사용하도록 주석처리)
- -Dflume.root.logger=DEBUG,console 옵션은 log를 file(logs/flume.logs)로 쌓지 않고, console로 출력만 하는 옵션임.
- 따라서 flume.log로 쌓고 싶다면 해당 옵션을 제거
> bin/flume-ng agent --conf ./conf/ -f conf/twitter.conf -n TwitterAgent
```
  -
  - 추가 설정
    * twitter에서 조회한 데이터는 FLUME_HOME/logs/flume.log에 저장됨.
    * 이 flume.log를 열어보면 "body: 4F 62 6A 01 02 16 61 76 72 6F 2E 73 63 68 65 6D"와 같은 문자열만 출력됨.
    * 해결방안
      * conf/log4j.properties 파일에서 "flume.root.logger=ALL,LOGFILE"로 변경
      * twitter
  - 결과 확인
   * TwitterAgent.sources.Twitter.keywords = tutorials point,java, bigdata, mapreduce, mahout, hbase, nosql에서 설정한 keyword에 대항하는 내용만 추출하고 있음.








#
